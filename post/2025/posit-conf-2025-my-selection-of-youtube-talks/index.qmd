---
title: "My selection of posit::conf(2025) talks to watch on YouTube"
subtitle: Four talks that I recommend among the 100+ videos available
date: 2025.12.05
categories: ['R','python']
---

Posit is the company behind RStudio and many widely-used R packages (such as _ggplot2_, the _tidyverse_). They also develop tools for other languages like Python (including their new data science IDE called [_Positron_](https://positron.posit.co), and _plotnine_, their port of _ggplot2_ to Python). In short, they create a lot of useful tools for the data science community.

Every year, they organise a conference, and they just released the recordings of this year's talks on [YouTube](https://www.youtube.com/playlist?list=PL9HYL-VRX0oTixlfDPCS5RW_F1pccERRe).

Here are my recommended talks (in no particular order):

- [How I got unstuck with Python (Julia Silge, Posit)](https://www.youtube.com/watch?v=pMVYl9fx1EE)

  As I mentioned in a previous post, I started learning Python after R and [found some key differences between the two languages challenging](/../link/2025/11/19/python-not-great-package-for-data-science/index.qmd). Finding the right tools was also challenging. Julia Silge highlights _pyenv_ as a turning point for her and it was for me too.
  
  On macOS, Python isn't pre-installed. Instead, it comes with the Command Line Tools, which must be installed separately. This made me feel uncomfortable. I didn't like messing with the system's python version (installing and uninstalling libraries). Also, the version was quite old (2.x) when I set up my local environment. Then I discovered _pyenv_ and the concept made sense : it's possible to install separate Python versions and to create isolated virtual environments. That's what I chose, and still use today. Though maybe not much longer.
  
  Julia Silge has moved to using _uv_. I have read so many good things about it. It is next on my list.
- [From messy to meaningful data: LLM-powered classification in R (Dylan Pieper)](https://www.youtube.com/watch?v=Lo4vewuapI8)

  The talk covers more, but it served as a good introduction to the [_ellmer_ package](https://ellmer.tidyverse.org) for me: how to interact with LLMs and get structured output in R. I also enjoyed the rest of the talk, especially the speaker's use of traditional ML models as benchmark against the LLM.
- [Posit and the modern data stack: Using Posit, Snowflake, and Databricks (James Blair)](https://www.youtube.com/watch?v=D3UAslMqEZc)

  Here, the title is a bit misleading. The talk focuses on something more exciting: a Positron feature called _Positron Assistant_, which provides LLM-assisted coding and data analysis.
  
  So far, these assistants required data to be available locally, which is a very unlikely scenario when working with enterprise data sources (data volumes are too large, downloading data is a privacy and security no-go).
  
  In the demo, James Blair shows how the assistant can work with the data available in Databricks or Snowflake. You need to set the connection up first and then it will work off of the table names, table schemas and a small sample of data. It then produces code that will run on the Databricks cluster for example.
  
  This feels like a nice step forward. It looks like the integration required a collaboration between Posit, Databricks and Snowflake. I'm still unclear about what enterprises need to do to implement this, and what metadata must be provided if any. Nevertheless, it's an interesting development. Of course, the performance of these LLMs in this scenario remains to be seen.
- [Expanding Quarto's Capabilities with Lua (Christophe Dervieux, Posit)](https://www.youtube.com/watch?v=u9ev3mvC-p0)

  I built my website using [Quarto](https://quarto.org). During the process, I encountered limitations and came across mentions of Lua filters and Quarto extensions. I decided to explore these more advanced topics later. My main goal was simply to get the site online.

  Christophe Dervieux's talk was a great introduction for me. While I'm not yet confident enough to develop with Lua filters, I now understand their role. It was helpful to see the pipeline that transforms `.qmd` documents into HTML, and where Lua filters come into play.