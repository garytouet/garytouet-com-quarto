{
  "hash": "c59b8eb26debb265174db42e06c4a5dc",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Analysing the sound of my fridge\"\nsubtitle: \"An excuse to try AI assisted coding with Mistral AI's model.\"\ndate: 2025.11.14\ncategories: [\"python\", \"ai assisted coding\", \"fun project\"]\n---\n\n## Backstory\n\nThis is a fun little project that I wanted to try for a bit now. You see, my fridge at home is very old. It has always been noisy, but I've been able to ignore it for many years.\n\nHowever, lately, something changed. It feels like the compressor runs louder and more frequently than before (too high of a frequency according to my nerves).\n\nI wanted to quantify two things:\n\n1. How long the compressor runs for each time,\n1. How long between each compressor run.\n\nI tried timing it manually, but I ran into issues and I didn't trust my measurements to be accurate. It's tedious to stay alert to a fridge's background hum while at home. ðŸ˜ƒ\n\nI wanted something more scientific and decided to use my iPad and the _Voice Memos_ app to record the sound. I had the vague idea that with the sound waves and timestamps I could reach my goals.\n\nTo make this easy, I wanted to record for rather long periods of time and to have clean recordings. So I left the iPad record while I was away for most of the day.\n\nMy first idea was to do my analysis with the _naked_ eye, but later I decided that it would be more fun to find a programmatic way to do it. I wanted to put my recently-acquired Mistral AI subscription to the test.\n\n## Mistral AI\n\nThe company and its models are often mentioned as [European alternatives to US firms and their models](https://madebuy.eu/european/ai-chatbots/). I wanted to give it a go and get familiar with it. In addition, Mistral and I are both born in France. These were enough reasons for me to sign up to the _Pro_ tier and to start experimenting.\n\nMy setup was:\n\n- Local machine (Macbook Air M3)\n- Working in Python inside Visual Studio Code\n- Using _Codestral_ within VS Code itself ^[This is not natively supported and needs to be configured via Continue.dev's extension ([documentation](https://docs.mistral.ai/capabilities/code_generation?tab=codestral-integrations#explorer-tabs-integrations)).]\n\n_Codestral_ is Mistral AI's `generative AI model explicitly designed for code generation tasks`. \n\nI went into this with prior Python coding knowledge, but I had never done any audio processing with it. So I gave the LLM a broad description of what I wanted to achieve. I didn't recommend packages, or specific methods. I only described what I had and what I wanted to achieve very broadly.\n\nInitial prompt:\n\n> I have a file \".m4a\" which is a recording of my fridge at home. I want to analyse the sound inside of this file to identify each time the fridge's compressor runs. The sound is very distinctive and I know that in this file there are two compressor runs which lasts very long times. What should I do in Python?\n\nI'll cut the story short, it disappointed me for the task at hand:\n\n1. I spent a few hours re-prompting, giving more precise instructions, explicitly asking for things and I never managed to get to something useful. The script was producing code that worked. All the packages used were safe and well-known. It was \"analysing\" my audio file and producing good data visualisations, but it couldn't identify the compressor runs properly.\n1. The code produced was very slow to run. It took between 5 and 10 mins each time. This made debugging and iterating very slow.\n1. Finally, in a different session, I tried prompting Mistral on the web. I supposed that my configuration in VS Code might be faulty. At first, it gave me interesting results, but I still stumbled in the last mile and couldn't get to something useful.\n\n> ![Last analysis generated before I gave up. The dashed red line is supposed to be a threshold used for detection. However, it does not seem to matter since data below the threshold is highlighted as _compressor run_...](output-codestral.png)\n\n## Claude to the rescue!\n\nFrustrated, I decided to copy and paste my initial prompt in Claude's web UI. I am not a paying subscriber so I am using `Claude Sonnet 4.5` on the free tier.\n\nAnd... To my surprise, it worked in 7 iterations. ðŸ¥²\n\n1. The very first script that it generated was much faster than the one from Codestral: less than ten seconds vs. several minutes before.\n1. Its first attempt produced a graph that didn't show which sections of the audio were identified as compressor runs. After I asked for it, it produced code that generated this graph. It was very easy to go from there to a finished analysis.\n\n    > ![](output-claude-first-attempt.png)\n1. It produced parameters that I could manually tune. It explained to me what these parameters were doing with example values to illustrate. For example:\n\n    > Lower (e.g., 60): More sensitive, catches quieter compressor runs but may have false positives\n    >\n    > Higher (e.g., 80-90): Only catches louder/clearer runs, fewer false positives\n1. After my 7th iteration, I had this output (pretty clean!):\n\n    > ![](output-claude-end.png)\n    > \n    > Total segments above threshold: 11\n    > \n    > Segments after filtering (â‰¥900s): 2\n    > \n    > Detected 2 compressor run(s):\n    >\n      > - Run 1: 18.07min - 49.33min (duration: 31.27min)\n      > - Run 2: 132.93min - 164.40min (duration: 31.47min)\n    >\n    > Time between runs:\n      > - Between Run 1 and Run 2: 83.60min\n\nThe code generated by Claude was better because:\n\n1. The detection method worked much better from the get-go. And the code generated ran fast from the start too.\n1. It used parameters whose values were based on my audio file. For example, the detection threshold was the nth percentile of a metric computed on the audio data itself. Manually tuning this percentile threshold was intuitive too.\n1. It even proactively handled an edge case: what if the recording stops before the end of a compressor run.\n1. I have the feeling that Claude was more responsive to my input and request for change too. Maybe this has to do with a difference in the length of the context windows (6 times longer for Claude Sonnet 4.5 vs. Codestral in my use case)[^tokens].\n\n[^tokens]: Mistral's documentation mentions [32k for Codestral](https://mistral.ai/fr/news/codestral). And Anthropic gives an example where [200k tokens are the size of the _standard_ window](https://docs.claude.com/en/docs/build-with-claude/context-windows#context-awareness-in-claude-sonnet-4-5-and-haiku-4-5), which would correspond to my free tier.\n\nIn any case, this provided me with good findings and lessons learned for future projects, especially if I want to persevere with Mistral.\n\n## Back to the analysis\n\nI pointed the final script (code generated by Claude with my manual parameter-tuning) to a recording that lasts eight hours and thirty minutes:\n\n::: {#f19f1f71 .cell execution_count=1}\n``` {.python .cell-code code-fold=\"true\"}\nimport librosa\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# 1. Load the audio file\naudio, sr = librosa.load(\"audio/fridge-1-clean.m4a\", sr=None)\n\n# 2. Calculate RMS energy over time windows\nframe_length = sr * 2  # Adjust this\nhop_length = sr * 4  # Adjust this\nrms = librosa.feature.rms(y=audio, frame_length=frame_length, hop_length=hop_length)[0]\n\n# 3. Detect high-energy periods (compressor running)\nthreshold = np.percentile(rms, 65)  # Adjust this\nis_running = rms > threshold\n\n# 4. Get time values\ntimes = librosa.frames_to_time(np.arange(len(rms)), sr=sr, hop_length=hop_length)\n\n# 5. Extract running segments\nrunning_segments = []\nstart = None\nfor i, running in enumerate(is_running):\n    if running and start is None:\n        start = i\n    elif not running and start is not None:\n        running_segments.append((times[start], times[i - 1]))\n        start = None\nif start is not None:  # Handle case where recording ends while running\n    running_segments.append((times[start], times[-1]))\n\n# 6. FILTER BY MINIMUM DURATION\nmin_duration = 900  # seconds - adjust this based on your compressor\nrunning_segments_filtered = [\n    (start, end) for start, end in running_segments if (end - start) >= min_duration\n]\n\n# 7. Create mask for filtered segments only\nis_running_filtered = np.zeros_like(is_running, dtype=bool)\nfor start_time, end_time in running_segments_filtered:\n    mask = (times >= start_time) & (times <= end_time)\n    is_running_filtered |= mask\n\n# 8. Visualize with highlighted compressor runs\nplt.figure(figsize=(9, 3))\n\n# Plot the RMS energy in minutes\ntimes_minutes = times / 60\nplt.plot(times_minutes, rms, color=\"blue\", linewidth=1, label=\"RMS Energy\")\n\n# Highlight filtered compressor running periods\nplt.fill_between(\n    times_minutes,\n    0,\n    rms,\n    where=is_running_filtered,\n    color=\"red\",\n    alpha=0.3,\n    label=\"Compressor Running\",\n)\n\nplt.axhline(threshold, color=\"orange\", linestyle=\"--\", linewidth=1, label=\"Threshold\")\nplt.xlabel(\"Time (minutes)\")\nplt.ylabel(\"RMS Energy\")\nplt.title(f\"Fridge Compressor Activity Detection (min duration: {min_duration}s)\")\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n# 9. Print detection summary\nprint(f\"\\nTotal segments above threshold: {len(running_segments)}\")\nprint(f\"Segments after filtering (â‰¥{min_duration}s): {len(running_segments_filtered)}\")\nprint(f\"\\nDetected {len(running_segments_filtered)} compressor run(s):\")\nfor i, (start_time, end_time) in enumerate(running_segments_filtered, 1):\n    duration_minutes = (end_time - start_time) / 60\n    start_minutes = start_time / 60\n    end_minutes = end_time / 60\n    print(\n        f\"  Run {i}: {start_minutes:.2f}min - {end_minutes:.2f}min (duration: {duration_minutes:.2f}min)\"\n    )\n\n# 10. Calculate and print time between runs\nif len(running_segments_filtered) > 1:\n    print(f\"\\nTime between runs:\")\n    for i in range(len(running_segments_filtered) - 1):\n        end_of_current = running_segments_filtered[i][1]\n        start_of_next = running_segments_filtered[i + 1][0]\n        gap_minutes = (start_of_next - end_of_current) / 60\n        print(f\"  Between Run {i + 1} and Run {i + 2}: {gap_minutes:.2f}min\")\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-2-output-1.png){width=854 height=278}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nTotal segments above threshold: 267\nSegments after filtering (â‰¥900s): 4\n\nDetected 4 compressor run(s):\n  Run 1: 67.60min - 103.00min (duration: 35.40min)\n  Run 2: 186.40min - 222.13min (duration: 35.73min)\n  Run 3: 307.53min - 341.60min (duration: 34.07min)\n  Run 4: 427.20min - 460.67min (duration: 33.47min)\n\nTime between runs:\n  Between Run 1 and Run 2: 83.40min\n  Between Run 2 and Run 3: 85.40min\n  Between Run 3 and Run 4: 85.60min\n```\n:::\n:::\n\n\nThe compressor runs are easily identifiable in the plot and, as the red zones show, the detection mechanism works very well at identifying them.\n\n## Conclusion \n\nWhat we were all dying to know is now revealed to us. The compressor in my fridge runs for roughly 33-35 minutes each time and it runs every 83-85 minutes.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}